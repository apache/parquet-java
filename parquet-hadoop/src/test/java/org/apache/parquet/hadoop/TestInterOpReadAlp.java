/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.apache.parquet.hadoop;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assume.assumeTrue;

import java.io.File;
import java.io.IOException;
import org.apache.hadoop.fs.Path;
import org.apache.parquet.example.data.Group;
import org.apache.parquet.hadoop.example.GroupReadSupport;
import org.junit.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Cross-compatibility test for ALP (Adaptive Lossless floating-Point) encoding.
 *
 * <p>This test reads ALP-encoded parquet files generated by Arrow C++ to verify
 * that the Java implementation can correctly decode them.
 *
 * <p>To run this test with local files generated by Arrow C++, set the environment variable
 * or system property:
 * <ul>
 *   <li>ALP_TEST_FILE - Path to an ALP-encoded parquet file</li>
 * </ul>
 *
 * <p>Once parquet-testing PR #100 is merged, this test will also support downloading
 * test files from the parquet-testing repository.
 *
 * @see <a href="https://github.com/apache/arrow/pull/48345">Arrow C++ ALP PR</a>
 * @see <a href="https://github.com/apache/parquet-testing/pull/100">parquet-testing ALP PR</a>
 */
public class TestInterOpReadAlp {
  private static final Logger LOG = LoggerFactory.getLogger(TestInterOpReadAlp.class);

  // TODO: Update these once parquet-testing PR #100 is merged
  // private static final String ALP_FLOAT_FILE = "alp_float.parquet";
  // private static final String ALP_DOUBLE_FILE = "alp_double.parquet";
  // private static final String CHANGESET = "TBD";
  // private final InterOpTester interop = new InterOpTester();

  /**
   * Get the path to a local ALP test file.
   *
   * @return Path to the test file, or null if not configured
   */
  private Path getLocalAlpTestFile() {
    String filePath = System.getProperty("ALP_TEST_FILE");
    if (filePath == null) {
      filePath = System.getenv("ALP_TEST_FILE");
    }
    if (filePath != null && new File(filePath).exists()) {
      return new Path(filePath);
    }
    return null;
  }

  /**
   * Test reading an ALP-encoded parquet file from a local path.
   *
   * <p>This test is skipped if no local file is configured.
   * Set ALP_TEST_FILE environment variable or system property to run.
   */
  @Test
  public void testReadLocalAlpFile() throws IOException {
    Path alpFile = getLocalAlpTestFile();
    assumeTrue("ALP_TEST_FILE not set or file does not exist, skipping test", alpFile != null);

    LOG.info("Reading ALP test file: {}", alpFile);

    int rowCount = 0;
    try (ParquetReader<Group> reader =
        ParquetReader.builder(new GroupReadSupport(), alpFile).build()) {
      Group group;
      while ((group = reader.read()) != null) {
        rowCount++;
        // Log first few rows for debugging
        if (rowCount <= 5) {
          LOG.info("Row {}: {}", rowCount, group);
        }
      }
    }

    LOG.info("Successfully read {} rows from ALP-encoded file", rowCount);
    assertTrue("Expected at least one row", rowCount > 0);
  }

  /**
   * Test reading ALP-encoded floats and comparing with PLAIN-encoded values.
   *
   * <p>This test expects a parquet file with columns:
   * <ul>
   *   <li>float_plain - PLAIN encoded float column</li>
   *   <li>float_alp - ALP encoded float column</li>
   * </ul>
   *
   * <p>Set ALP_TEST_FILE to a file with these columns to run this test.
   */
  @Test
  public void testReadAlpFloatCompareWithPlain() throws IOException {
    Path alpFile = getLocalAlpTestFile();
    assumeTrue("ALP_TEST_FILE not set or file does not exist, skipping test", alpFile != null);

    LOG.info("Comparing ALP vs PLAIN float encoding from: {}", alpFile);

    int rowCount = 0;
    int mismatchCount = 0;
    try (ParquetReader<Group> reader =
        ParquetReader.builder(new GroupReadSupport(), alpFile).build()) {
      Group group;
      while ((group = reader.read()) != null) {
        rowCount++;
        try {
          // Try to read both columns - may not exist depending on file format
          float plainVal = group.getFloat("float_plain", 0);
          float alpVal = group.getFloat("float_alp", 0);

          // Compare bit-exact values
          if (Float.floatToRawIntBits(plainVal) != Float.floatToRawIntBits(alpVal)) {
            mismatchCount++;
            if (mismatchCount <= 5) {
              LOG.warn(
                  "Float mismatch at row {}: plain={} (bits={}), alp={} (bits={})",
                  rowCount,
                  plainVal,
                  Float.floatToRawIntBits(plainVal),
                  alpVal,
                  Float.floatToRawIntBits(alpVal));
            }
          }
        } catch (RuntimeException e) {
          // Columns may not exist in this file format
          if (rowCount == 1) {
            LOG.info("Could not compare float columns: {}", e.getMessage());
          }
          break;
        }
      }
    }

    if (mismatchCount > 0) {
      LOG.error("Found {} float mismatches out of {} rows", mismatchCount, rowCount);
    }
    assertEquals("Float values should match between PLAIN and ALP encoding", 0, mismatchCount);
  }

  /**
   * Test reading ALP-encoded doubles and comparing with PLAIN-encoded values.
   *
   * <p>This test expects a parquet file with columns:
   * <ul>
   *   <li>double_plain - PLAIN encoded double column</li>
   *   <li>double_alp - ALP encoded double column</li>
   * </ul>
   *
   * <p>Set ALP_TEST_FILE to a file with these columns to run this test.
   */
  @Test
  public void testReadAlpDoubleCompareWithPlain() throws IOException {
    Path alpFile = getLocalAlpTestFile();
    assumeTrue("ALP_TEST_FILE not set or file does not exist, skipping test", alpFile != null);

    LOG.info("Comparing ALP vs PLAIN double encoding from: {}", alpFile);

    int rowCount = 0;
    int mismatchCount = 0;
    try (ParquetReader<Group> reader =
        ParquetReader.builder(new GroupReadSupport(), alpFile).build()) {
      Group group;
      while ((group = reader.read()) != null) {
        rowCount++;
        try {
          // Try to read both columns - may not exist depending on file format
          double plainVal = group.getDouble("double_plain", 0);
          double alpVal = group.getDouble("double_alp", 0);

          // Compare bit-exact values
          if (Double.doubleToRawLongBits(plainVal) != Double.doubleToRawLongBits(alpVal)) {
            mismatchCount++;
            if (mismatchCount <= 5) {
              LOG.warn(
                  "Double mismatch at row {}: plain={} (bits={}), alp={} (bits={})",
                  rowCount,
                  plainVal,
                  Double.doubleToRawLongBits(plainVal),
                  alpVal,
                  Double.doubleToRawLongBits(alpVal));
            }
          }
        } catch (RuntimeException e) {
          // Columns may not exist in this file format
          if (rowCount == 1) {
            LOG.info("Could not compare double columns: {}", e.getMessage());
          }
          break;
        }
      }
    }

    if (mismatchCount > 0) {
      LOG.error("Found {} double mismatches out of {} rows", mismatchCount, rowCount);
    }
    assertEquals("Double values should match between PLAIN and ALP encoding", 0, mismatchCount);
  }

  /**
   * Test reading any ALP-encoded file and verify basic functionality.
   *
   * <p>This test reads all float and double columns from the file
   * and verifies the values are valid (not corrupted).
   */
  @Test
  public void testReadAlpVerifyValues() throws IOException {
    Path alpFile = getLocalAlpTestFile();
    assumeTrue("ALP_TEST_FILE not set or file does not exist, skipping test", alpFile != null);

    LOG.info("Verifying ALP values from: {}", alpFile);

    int rowCount = 0;
    int floatCount = 0;
    int doubleCount = 0;
    int nanCount = 0;
    int infCount = 0;

    try (ParquetReader<Group> reader =
        ParquetReader.builder(new GroupReadSupport(), alpFile).build()) {
      Group group;
      while ((group = reader.read()) != null) {
        rowCount++;

        // Try to read float columns
        for (int i = 0; i < group.getType().getFieldCount(); i++) {
          String fieldName = group.getType().getFieldName(i);
          try {
            if (group.getType().getType(i).asPrimitiveType().getPrimitiveTypeName()
                == org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.FLOAT) {
              float val = group.getFloat(fieldName, 0);
              floatCount++;
              if (Float.isNaN(val)) nanCount++;
              if (Float.isInfinite(val)) infCount++;
            } else if (group.getType().getType(i).asPrimitiveType().getPrimitiveTypeName()
                == org.apache.parquet.schema.PrimitiveType.PrimitiveTypeName.DOUBLE) {
              double val = group.getDouble(fieldName, 0);
              doubleCount++;
              if (Double.isNaN(val)) nanCount++;
              if (Double.isInfinite(val)) infCount++;
            }
          } catch (Exception e) {
            // Skip fields that can't be read
          }
        }
      }
    }

    LOG.info(
        "Read {} rows, {} floats, {} doubles, {} NaNs, {} Infs",
        rowCount,
        floatCount,
        doubleCount,
        nanCount,
        infCount);
    assertTrue("Expected at least one row", rowCount > 0);
  }

  // TODO: Uncomment and update once parquet-testing PR #100 is merged
  /*
  @Test
  public void testReadAlpFromParquetTesting() throws IOException {
  Path alpFloatFile = interop.GetInterOpFile(ALP_FLOAT_FILE, CHANGESET);
  // Test implementation here
  }
  */
}
